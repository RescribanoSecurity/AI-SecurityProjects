# Secure RAG from Scratch (Technical Documentation)

ðŸ“„ This documentation is available in:
- ðŸ‡¬ðŸ‡§ English (this document)
- ðŸ‡ªðŸ‡¸ EspaÃ±ol â†’ README_ES.md

---

## Purpose of this project

This project implements a **secure Retrieval-Augmented Generation (RAG) system** from scratch, designed to:

- Understand how RAG pipelines work end to end
- Apply real security controls to LLM-based systems
- Separate security logic from infrastructure and providers
- Evolve cleanly from local development to cloud environments

The focus is on architecture, security decisions, and explainability.

---
```mermaid
flowchart LR
    A --> B
---

## Execution modes (APP_MODE)

local_basic  â€“ Baseline RAG with input security  
local_secure â€“ Adds output security (PII) and audit logging

---

## Project Structure

- app/main.py â€“ FastAPI entry point and orchestration
- app/security.py â€“ Prompt injection detection
- app/rag.py â€“ Core RAG pipeline
- app/vector_store.py â€“ In-memory vector store
- app/llm_client.py â€“ Mock LLM client
- app/security_output.py â€“ PII detection and redaction
- app/audit.py â€“ Structured audit logging

---

## Security Controls

- Prompt injection detection
- PII detection and redaction
- Structured audit logging

---

## Testing

Manual tests cover:
- Prompt injection blocking
- PII redaction
- Audit log generation

---

## Lessons Learned

- External dependencies can block development
- Local-first design accelerates security testing
- Security must be independent of LLM providers

---

## Future Work

- Cloud vector stores
- Dockerized deployment
- CI/CD and security testing
