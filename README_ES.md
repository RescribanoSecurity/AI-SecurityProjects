# AI Security Learning Lab  
*(LLMs Â· Secure RAG Â· Cloud Â· MLOps)*

Este README estÃ¡ disponible en:
- ğŸ‡¬ğŸ‡§ EN English â†’ [README.md](README.md)
- ğŸ‡ªğŸ‡¸ ES EspaÃ±ol (este documento)

---

## VisiÃ³n General

Este repositorio es mi **laboratorio personal de aprendizaje en Seguridad de IA** y **repositorio Ã­ndice**, que documenta mi evoluciÃ³n desde **Cloud Security** hacia **AI / LLM Security**, con el objetivo a largo plazo de un perfil de **AI Cloud Security Architect**.

El enfoque es **construir sistemas de IA reales desde cero**, hacer explÃ­citas las **decisiones arquitectÃ³nicas y de seguridad**, validarlas mediante pruebas prÃ¡cticas y documentar tanto **los resultados como los errores**.

Este **no es un repositorio de tutoriales**.  
Es una exploraciÃ³n **ingenieril y security-first** de sistemas modernos basados en LLMs.

---

## Objetivos de Aprendizaje

- Comprender cÃ³mo funcionan internamente los **LLMs** (contexto, prompts, generaciÃ³n).
- DiseÃ±ar y construir **pipelines RAG (Retrieval-Augmented Generation) seguros**.
- Aplicar **controles prÃ¡cticos de seguridad en IA**, inspirados en **OWASP LLM Top 10**:
  - Prompt injection y jailbreaks
  - Fugas de datos y exposiciÃ³n de PII
  - Riesgos en la ingesta y data poisoning
  - PrevenciÃ³n de abuso y auditabilidad
- Preparar sistemas para **entornos tipo enterprise**:
  - ConfiguraciÃ³n multi-entorno
  - Observabilidad y logging estructurado
  - Arquitectura preparada para cloud
  - Fundamentos de MLOps

---

## Proyectos

### ğŸ”¬ Secure RAG from Scratch â€” VersiÃ³n 1 (Laboratorio Legacy)
ğŸ“ `secure-rag-from-scratch/`

Este proyecto representa la **primera iteraciÃ³n exploratoria** de Secure RAG.

Su objetivo fue:
- Entender los mecanismos bÃ¡sicos de los sistemas RAG
- Experimentar con **controles iniciales de seguridad de entrada**
- Validar supuestos antes de introducir mayor complejidad de infraestructura

**CaracterÃ­sticas principales de V1:**
- EjecuciÃ³n local
- Vector store en memoria
- LLM simulado (independiente del proveedor)
- DetecciÃ³n bÃ¡sica de prompt injection
- Pruebas manuales y documentaciÃ³n

âš ï¸ **Esta versiÃ³n se considera actualmente un laboratorio legacy.**

ğŸ‘‰ La versiÃ³n activa y evolucionada es **Secure RAG v2**, mantenida en un repositorio independiente.

---

### ğŸš€ Secure RAG from Scratch â€” VersiÃ³n 2 (Proyecto Principal)

ğŸ”— Repositorio:  
https://github.com/RescribanoSecurity/secure-rag-from-scratch-v2

Secure RAG v2 es el **proyecto principal y mÃ¡s maduro**, evolucionado directamente a partir de las lecciones aprendidas en V1.

**Ãreas clave:**
- Arquitectura modular de pipeline RAG
- Controles de seguridad de entrada **y salida**
- DetecciÃ³n, redacciÃ³n y bloqueo de PII
- Mapeo con OWASP LLM Top 10
- Infraestructura dockerizada
- Base de datos vectorial real (Qdrant)
- Trazabilidad y auditorÃ­a de peticiones
- ValidaciÃ³n visual mediante interfaz Streamlit

Este proyecto es:
- Ejecutable
- Testeable
- Basado en evidencia
- Transparente sobre lo que estÃ¡ implementado y lo que no

ğŸ“„ La documentaciÃ³n tÃ©cnica completa, capturas y presentaciones se mantienen **dentro del repositorio de la V2**.

---

## FilosofÃ­a de DiseÃ±o

- **EvoluciÃ³n por fases**: cada fase es estable, revisable y extensible.
- **La seguridad como pilar central**, no como aÃ±adido.
- **Arquitectura desacoplada**: los controles de seguridad no dependen del proveedor de LLM ni del vector store.
- **Local-first, cloud-ready**: reducir complejidad inicial sin cerrar puertas al escalado.
- **Los fallos se documentan**, no se ocultan.

---

## Roadmap (Alto Nivel)

- [x] Baseline Secure RAG local (V1)
- [x] Controles de seguridad de entrada
- [x] Seguridad de salida (detecciÃ³n, redacciÃ³n y bloqueo de PII)
- [x] ValidaciÃ³n manual con evidencia documentada
- [ ] Vector stores cloud-native (OpenSearch / Azure AI Search)
- [ ] AutenticaciÃ³n y logging con identidad
- [ ] Logs de auditorÃ­a persistentes
- [ ] CI/CD y testing automÃ¡tico de seguridad
- [ ] Threat modeling y enforcement completo de OWASP LLM Top 10

---

## Por quÃ© existe este repositorio

Los sistemas de IA modernos **van a ser atacados**.

Saber:
- diseÃ±arlos de forma segura,
- validar controles de seguridad,
- detectar abusos,
- auditar comportamientos,
- y evolucionar arquitecturas con criterio,

se estÃ¡ convirtiendo en una **competencia clave en seguridad**.

Este repositorio documenta ese camino.
