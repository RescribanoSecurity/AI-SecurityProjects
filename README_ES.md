# Laboratorio de Seguridad en IA (LLMs Â· RAG Seguro Â· Cloud Â· MLOps)

ğŸ“„ Este README estÃ¡ disponible en:
- ğŸ‡¬ğŸ‡§ English â†’ [README.md](README.md)
- ğŸ‡ªğŸ‡¸ EspaÃ±ol (este documento)

---

## VisiÃ³n general

Este repositorio es mi **laboratorio personal de aprendizaje en seguridad de Inteligencia Artificial**, con el objetivo de evolucionar desde **Cloud Security** hacia perfiles de **AI / LLM Security** o **AI Cloud Security Architect**.

El enfoque es **construir sistemas reales desde cero**, documentando decisiones tÃ©cnicas, errores reales y controles de seguridad aplicables a entornos empresariales.

No es un repositorio de tutoriales.  
Es un **ejercicio de ingenierÃ­a y seguridad aplicada**.

---

## Objetivos de aprendizaje

- Comprender cÃ³mo funcionan los **LLMs** (contexto, prompts, generaciÃ³n, limitaciones).
- DiseÃ±ar y construir **RAGs seguros (Retrieval-Augmented Generation)**.
- Aplicar controles reales de seguridad inspirados en **OWASP LLM Top 10**:
  - Prompt Injection y Jailbreaks
  - Fugas de informaciÃ³n y PII
  - Riesgos en ingestiÃ³n de datos
  - AuditorÃ­a y trazabilidad
- Preparar arquitecturas **listas para entornos cloud empresariales**.

---

## Proyectos

### ğŸ” Secure RAG from Scratch
ğŸ“‚ `secure-rag-from-scratch/`

Sistema RAG seguro construido de forma incremental:

- **Fase 1 â€“ Baseline local**
  - Vector store en memoria
  - LLM simulado (mock)
  - Seguridad de entrada (prompt injection)

- **Fase 2 â€“ Modo local seguro**
  - Seguridad de salida (detecciÃ³n y redacciÃ³n de PII)
  - AuditorÃ­a estructurada
  - ActivaciÃ³n por entorno (`APP_MODE`)

ğŸ“˜ DocumentaciÃ³n tÃ©cnica:
- ğŸ‡¬ğŸ‡§ [secure-rag-from-scratch/README.md](secure-rag-from-scratch/README.md)
- ğŸ‡ªğŸ‡¸ [secure-rag-from-scratch/README_ES.md](secure-rag-from-scratch/README_ES.md)

---

## FilosofÃ­a de diseÃ±o

- EvoluciÃ³n por fases claras
- Seguridad como capa transversal
- SeparaciÃ³n entre lÃ³gica, infraestructura y proveedor
- DiseÃ±o local-first pero cloud-ready

---

## Roadmap

- [x] RAG local funcional
- [x] Seguridad de salida y auditorÃ­a
- [ ] AbstracciÃ³n de infraestructura
- [ ] Contenedores y despliegue cloud
- [ ] IntegraciÃ³n con servicios vectoriales empresariales
- [ ] AutomatizaciÃ³n y MLOps

---

## Por quÃ© existe este repositorio

Los sistemas de IA:
- van a fallar,
- van a ser atacados,
- y van a manejar datos sensibles.

Este repositorio documenta cÃ³mo **diseÃ±arlos y protegerlos de forma responsable**.

---

## Licencia
MIT
